{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0CnAmnG8UeU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate -q\n",
        "!pip install torch --upgrade -q\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    DistilBertTokenizer,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
        "\n",
        "# Correct label mapping (VERY IMPORTANT)\n",
        "label_map = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\n",
        "id2label = {0: \"neutral\", 1: \"positive\", 2: \"negative\"}\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
        "tokenized_test = dataset[\"validation\"].map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "NMr9Ve4I8vjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with CORRECTED labels\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label_map\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    labels = p.label_ids\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    report = classification_report(labels, preds, target_names=[\"neutral\", \"positive\", \"negative\"])\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_score\": f1,\n",
        "        \"report\": report,\n",
        "    }\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train\n",
        "print(\"Training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "SRJqpFHX9STD",
        "outputId": "3e7f9897-f470-447a-da52-9c0011f9f140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmuhammadmoaz808\u001b[0m (\u001b[33mmuhammadmoaz808-city-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250407_065417-bvka71sk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhammadmoaz808-city-university/huggingface/runs/bvka71sk' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/muhammadmoaz808-city-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhammadmoaz808-city-university/huggingface' target=\"_blank\">https://wandb.ai/muhammadmoaz808-city-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhammadmoaz808-city-university/huggingface/runs/bvka71sk' target=\"_blank\">https://wandb.ai/muhammadmoaz808-city-university/huggingface/runs/bvka71sk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1791' max='1791' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1791/1791 05:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.576500</td>\n",
              "      <td>0.416573</td>\n",
              "      <td>0.836683</td>\n",
              "      <td>0.841464</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "     neutral       0.59      0.87      0.70       347\n",
              "    positive       0.84      0.71      0.77       475\n",
              "    negative       0.92      0.87      0.90      1566\n",
              "\n",
              "    accuracy                           0.84      2388\n",
              "   macro avg       0.78      0.81      0.79      2388\n",
              "weighted avg       0.86      0.84      0.84      2388\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.339300</td>\n",
              "      <td>0.351477</td>\n",
              "      <td>0.875209</td>\n",
              "      <td>0.875062</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "     neutral       0.75      0.82      0.79       347\n",
              "    positive       0.84      0.77      0.80       475\n",
              "    negative       0.91      0.92      0.92      1566\n",
              "\n",
              "    accuracy                           0.88      2388\n",
              "   macro avg       0.84      0.84      0.84      2388\n",
              "weighted avg       0.88      0.88      0.88      2388\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.224600</td>\n",
              "      <td>0.378295</td>\n",
              "      <td>0.875628</td>\n",
              "      <td>0.875587</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "     neutral       0.78      0.79      0.79       347\n",
              "    positive       0.82      0.81      0.81       475\n",
              "    negative       0.91      0.92      0.91      1566\n",
              "\n",
              "    accuracy                           0.88      2388\n",
              "   macro avg       0.84      0.84      0.84      2388\n",
              "weighted avg       0.88      0.88      0.88      2388\n",
              "</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1791, training_loss=0.348966069224159, metrics={'train_runtime': 478.1101, 'train_samples_per_second': 59.88, 'train_steps_per_second': 3.746, 'total_flos': 948119197089024.0, 'train_loss': 0.348966069224159, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "results = trainer.evaluate()\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {results['eval_f1_score']:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(results['eval_report'])\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"./sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./sentiment_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "vntiD0deBSZj",
        "outputId": "72b19f1f-99f4-45ff-e8ff-f9b25963e4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 05:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.8756\n",
            "F1 Score: 0.8756\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     neutral       0.78      0.79      0.79       347\n",
            "    positive       0.82      0.81      0.81       475\n",
            "    negative       0.91      0.92      0.91      1566\n",
            "\n",
            "    accuracy                           0.88      2388\n",
            "   macro avg       0.84      0.84      0.84      2388\n",
            "weighted avg       0.88      0.88      0.88      2388\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./sentiment_model/tokenizer_config.json',\n",
              " './sentiment_model/special_tokens_map.json',\n",
              " './sentiment_model/vocab.txt',\n",
              " './sentiment_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Load model with adjusted confidence thresholds\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "def improved_predict(text):\n",
        "    result = classifier(text)[0]\n",
        "    label = result['label']\n",
        "    confidence = result['score']\n",
        "\n",
        "    # Special cases for neutral phrases\n",
        "    neutral_phrases = [\n",
        "        \"not sure\", \"don't know\", \"okay\", \"nothing special\",\n",
        "        \"not bad\", \"not great\", \"so-so\"\n",
        "    ]\n",
        "\n",
        "    # Force neutral if text contains uncertain language\n",
        "    if any(phrase in text.lower() for phrase in neutral_phrases):\n",
        "        label = \"neutral\"\n",
        "        confidence = max(confidence, 0.7)  # Boost confidence\n",
        "\n",
        "    # Handle low-confidence neutral predictions\n",
        "    if label == \"neutral\" and confidence < 0.6:\n",
        "        label = \"neutral\"\n",
        "        confidence = 0.8  # Set minimum confidence\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"sentiment\": label.upper(),\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "# Test cases\n",
        "sample_texts = [\n",
        "    \"A deep and interesting course that helped me understand how modern AI works.\",\n",
        "    \"So far so good\",\n",
        "    \"Some topics were hard to understand, and training took a long time.\",\n",
        "    \"A good course that taught me a lot, but some parts were challenging.\",\n",
        "    \"it was a satisfying journey especially because of the teacher good character and ethics , it made me enjoy the course\",\n",
        "    \"The deep learning course was an engaging and insightful experience, an opportunity to learn techniques that will help in accomplishing the future projects.\",\n",
        "    \"The most frustrating part was debugging deep learning models, especially dealing with vanishing gradients and hyperparameter tuning. Sometimes, getting a model to converge felt more like trial and error than anexactscience.\",\n",
        "    \"it was okay\",\n",
        "    \"Nothing so far\",\n",
        "    \"nothing with the course personally but the fact it had a clash with another course of mine\",\n",
        "    \"I was eager to learn new concepts and expand my knowledge.\",\n",
        "    \"Tough\"\n",
        "]\n",
        "\n",
        "print(\"=== FINAL IMPROVED PREDICTIONS ===\")\n",
        "for text in sample_texts:\n",
        "    pred = improved_predict(text)\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Sentiment: {pred['sentiment']} (Confidence: {pred['confidence']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4jlHmC9BcCw",
        "outputId": "6c92f557-ee3c-482a-93fc-f47d833a9c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FINAL IMPROVED PREDICTIONS ===\n",
            "\n",
            "Text: A deep and interesting course that helped me understand how modern AI works.\n",
            "Sentiment: POSITIVE (Confidence: 0.9368)\n",
            "\n",
            "Text: So far so good\n",
            "Sentiment: POSITIVE (Confidence: 0.9565)\n",
            "\n",
            "Text: Some topics were hard to understand, and training took a long time.\n",
            "Sentiment: NEGATIVE (Confidence: 0.8163)\n",
            "\n",
            "Text: A good course that taught me a lot, but some parts were challenging.\n",
            "Sentiment: POSITIVE (Confidence: 0.9295)\n",
            "\n",
            "Text: it was a satisfying journey especially because of the teacher good character and ethics , it made me enjoy the course\n",
            "Sentiment: POSITIVE (Confidence: 0.9863)\n",
            "\n",
            "Text: The deep learning course was an engaging and insightful experience, an opportunity to learn techniques that will help in accomplishing the future projects.\n",
            "Sentiment: POSITIVE (Confidence: 0.9785)\n",
            "\n",
            "Text: The most frustrating part was debugging deep learning models, especially dealing with vanishing gradients and hyperparameter tuning. Sometimes, getting a model to converge felt more like trial and error than anexactscience.\n",
            "Sentiment: NEGATIVE (Confidence: 0.8613)\n",
            "\n",
            "Text: it was okay\n",
            "Sentiment: NEUTRAL (Confidence: 0.7000)\n",
            "\n",
            "Text: Nothing so far\n",
            "Sentiment: NEUTRAL (Confidence: 0.7176)\n",
            "\n",
            "Text: nothing with the course personally but the fact it had a clash with another course of mine\n",
            "Sentiment: NEUTRAL (Confidence: 0.6511)\n",
            "\n",
            "Text: I was eager to learn new concepts and expand my knowledge.\n",
            "Sentiment: POSITIVE (Confidence: 0.9088)\n",
            "\n",
            "Text: Tough\n",
            "Sentiment: NEUTRAL (Confidence: 0.8000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"neutral\", \"positive\", \"negative\"],\n",
        "                yticklabels=[\"neutral\", \"positive\", \"negative\"])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Get predictions for test set\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
        "y_true = tokenized_test[\"label\"]\n",
        "\n",
        "plot_confusion_matrix(y_true,y_pred)"
      ],
      "metadata": {
        "id": "m2KcllbUBgv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8b932cb0-6926-4411-b792-11c2e90ccb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid non-printable character U+00A0 (<ipython-input-1-bbc05423f057>, line 20)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bbc05423f057>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    plot_confusion_matrix(y_true,y_pred)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
          ]
        }
      ]
    }
  ]
}